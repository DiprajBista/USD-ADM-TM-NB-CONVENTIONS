{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2e2e6edff40>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_cur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "conventions\n"
     ]
    }
   ],
   "source": [
    "# The SQLite database\n",
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()\n",
    "\n",
    "# Query to list all table names\n",
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = convention_cur.fetchall()\n",
    "\n",
    "# Table names\n",
    "print(\"Tables in the database:\")\n",
    "for table in tables:\n",
    "    print(table[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in the 'conventions' table:\n",
      "party\n",
      "night\n",
      "speaker\n",
      "speaker_count\n",
      "time\n",
      "text\n",
      "text_len\n",
      "file\n"
     ]
    }
   ],
   "source": [
    "table_name = 'conventions'\n",
    "\n",
    "# Query to get the column names of the specific table\n",
    "convention_cur.execute(f\"PRAGMA table_info({table_name});\")\n",
    "columns = convention_cur.fetchall()\n",
    "\n",
    "# Display the column names\n",
    "print(f\"\\nColumns in the '{table_name}' table:\")\n",
    "for column in columns:\n",
    "    print(column[1])  # Column names are in the second index (index 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'party', 'TEXT', 0, None, 0),\n",
       " (1, 'night', 'INTEGER', 0, None, 0),\n",
       " (2, 'speaker', 'TEXT', 0, None, 0),\n",
       " (3, 'speaker_count', 'INTEGER', 0, None, 0),\n",
       " (4, 'time', 'TEXT', 0, None, 0),\n",
       " (5, 'text', 'TEXT', 0, None, 0),\n",
       " (6, 'text_len', 'TEXT', 0, None, 0),\n",
       " (7, 'file', 'TEXT', 0, None, 0)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Query to see the column names in the 'conventions' table\n",
    "convention_cur.execute(\"PRAGMA table_info(conventions)\").fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\bista/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bista/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foreign prince', 'Republican']\n",
      "['reproductive justice', 'Democratic']\n",
      "['mission fight future equal ideals founders hopes children sacrifices veterans brave men women uniform families', 'Democratic']\n",
      "['black americans standing native land probably represent oregon dual viruses racism laid bare equal healthcare access deaths communities color', 'Democratic']\n",
      "['joe purpose always driven forward strength unstoppable faith unshakable politicians political parties even providence god faith us yes many classrooms quiet right playgrounds still listen closely hear sparks change air across country educators parents first responders americans walks life putting shoulders back fighting given need leadership worthy nation worthy honest leadership bring us back together recover pandemic prepare whatever else next dr', 'Democratic']\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Connect to the database\n",
    "#convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "#convention_cur = convention_db.cursor()\n",
    "\n",
    "# Initialize an empty list to hold the processed data\n",
    "convention_data = []\n",
    "\n",
    "# Query the 'conventions' table to get text and party columns\n",
    "query_results = convention_cur.execute(\n",
    "    '''\n",
    "    SELECT text, party FROM conventions\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Set of stopwords for filtering\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "# Convert to lowercase and tokenize\n",
    "# Remove stopwords and non-alphabetic tokens\n",
    "def clean_tokenize(text):\n",
    "    tokens = word_tokenize(text.lower())  \n",
    "    cleaned_tokens = [word for word in tokens if word.isalpha() \n",
    "                      and word not in stop_words]  \n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Process the query results\n",
    "for row in query_results:\n",
    "    speech_text = row[0]  # text\n",
    "    party = row[1]  # party affiliation\n",
    "    \n",
    "    # Clean and tokenize the speech text\n",
    "    cleaned_speech = clean_tokenize(speech_text)\n",
    "    \n",
    "    # Append the cleaned text and party to the convention_data list\n",
    "    convention_data.append([cleaned_speech, party])\n",
    "\n",
    "# Take a random sample of 5 speeches\n",
    "random_sample = random.choices(convention_data, k=5)\n",
    "for speech in random_sample:\n",
    "    print(speech)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['love heart', 'Democratic'],\n",
       " ['rhode island ocean state restaurant fishing industry decimated pandemic lucky governor gina raimondo whose program lets fishermen sell catches directly public state appetizer calamari available states calamari comeback state rhode island casts vote bernie sanders votes next president joe biden',\n",
       "  'Democratic'],\n",
       " ['knows like send child war', 'Democratic'],\n",
       " ['america', 'Democratic'],\n",
       " ['trillions dollars repatriated back united states sitting foreign lands far long america became envy world renewed strength came leverage president demanded allies pay fair share defense western world father rebuilt mighty american military adding new jets aircraft carriers increased wages incredible men women uniform expanded military defense budget billion per year america longer weak eye enemy moment president trump ordered special forces kill deadliest terrorists planet day mighty moab dropped insurgent camps day america took stance never defeated enemy soleimani dead issue issue economy wall military trade deals tax cuts supreme court justices va hospitals prescription drugs school choice right try moving embassy jerusalem peace middle east wars finally ended promises made promises first time kept',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2236 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, \n",
    "      we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_features(text, fw):\n",
    "    \"\"\"Given some text, this returns a dictionary holding the feature words.\n",
    "    \n",
    "    Args: \n",
    "        * text: a piece of text in a continuous string. Assumes\n",
    "        text has been cleaned and case folded.\n",
    "        * fw: the *feature words* that we're considering. A word \n",
    "        in `text` must be in fw in order to be returned. This \n",
    "        prevents us from considering very rarely occurring words.\n",
    "    \n",
    "    Returns: \n",
    "        A dictionary with the words in `text` that appear in `fw`. \n",
    "        Words are only counted once. \n",
    "        If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "        then this would return a dictionary of \n",
    "        {'quick' : True,\n",
    "         'fox' :    True}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Create a dictionary for features found in the text\n",
    "    ret_dict = {word: True for word in words if word in fw}\n",
    "    \n",
    "    return ret_dict\n",
    "\n",
    "# test cases\n",
    "assert(len(feature_words) > 0)\n",
    "assert(conv_features(\"donald is the president\", feature_words) == {'donald': True, 'president': True})\n",
    "assert(conv_features(\"some people in america are citizens\", \n",
    "                     feature_words) == {'people': True, 'america': True, 'citizens': True})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes Classifier: 49.40%\n",
      "\n",
      "Most Informative Features:\n",
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     27.1 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.8 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create the feature set for each piece of text\n",
    "featuresets = [(conv_features(text, feature_words), party) \n",
    "               for (text, party) in convention_data]\n",
    "\n",
    "# Shuffle the feature sets and split into training and test sets\n",
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "# Define the test size \n",
    "test_size = 500\n",
    "\n",
    "# Split the data into test and training sets\n",
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "print(f\"Accuracy of the Naive Bayes Classifier: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the most informative features\n",
    "print(\"\\nMost Informative Features:\")\n",
    "classifier.show_most_informative_features(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "The  Accuracy of the Naive Bayes Classifier is 49.40% which can be explained as the model performance with the given dataset. The low accuracy indicates that there is a challenged in separating Democratic and Republican based on the features derived from the text dataset. This needs to be imporved so that we can increase the accuracy of the model. \n",
    "\n",
    "Some of the intersting obaservation were the assocaition of word \"China\" with the Republican party and word \"vote\" associated with Democratic speeches. Some of the pupular words from Republican speeches are \"enforcement\", \"destroy\", \"freedoms\", \"crime\", etc. Simialrly, the frequent words associated with Democratic speeches are \"climate\", \"votes\", etc. The use of the words from both Republican speeches and Democratic speeches represents the political opinions and  ideology of the repective parties. For example, climate change and voting rights are the major plocies of the Democrats. \n",
    "\n",
    "I also think there are intersting findings in this analysis. \"Vote\" should be general term but this is more tilted towards the Democrats. The words \"media\" is frequnt in Republican but they are mostly critisized for being conservative on various issues. Similarly, it is somewhat odd to see the words as \"crime\",\"defund\", \"destroy\" paired with \"freedom\",\"greatness\" beind tied to one party. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast https\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether https\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget https\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide help putting lives line https\n",
      "Actual party is Republican and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: let make even greater kag https\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: cavs tie series repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue https\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: really close raised toward match right whoot majors room help us get https https\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potus plan expand offshore drilling opened public days march share oppose proposed program directly trump administration comments made email mail https\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastla years eastside commitment amp saluted community leaders last night awards dinner https\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# NLTK data \n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Clean and tokenize function\n",
    "def clean_tokenize(text):\n",
    "    if isinstance(text, bytes):  \n",
    "        text = text.decode('utf-8')  \n",
    "    tokens = word_tokenize(text.lower())  \n",
    "    cleaned_tokens = [word for word in tokens \n",
    "                      if word.isalpha() and word not in stop_words]  \n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Connect to the congressional tweets database\n",
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()\n",
    "\n",
    "# Execute the query to get the tweets and party affiliation\n",
    "results = cong_cur.execute('''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results)  \n",
    "\n",
    "# Close the connection after retrieving the data\n",
    "cong_db.close()\n",
    "\n",
    "# Clean and tokenize the tweet data\n",
    "tweet_data = []\n",
    "for row in results:\n",
    "    tweet_text = row[2]  \n",
    "    party = row[1]  \n",
    "\n",
    "    cleaned_tweet = clean_tokenize(tweet_text)  \n",
    "    tweet_data.append([cleaned_tweet, party])  \n",
    "\n",
    "# Split the data into features and labels\n",
    "X = [tweet[0] for tweet in tweet_data]  \n",
    "y = [tweet[1] for tweet in tweet_data]  \n",
    "\n",
    "# Vectorize the tweets using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_vec, y)\n",
    "\n",
    "# Test the classifier on a random sample of 10 tweets\n",
    "random.seed(20201014)\n",
    "tweet_data_sample = random.choices(tweet_data, k=10)\n",
    "\n",
    "for tweet, party in tweet_data_sample:\n",
    "    tweet_vec = vectorizer.transform([tweet])  \n",
    "    estimated_party = clf.predict(tweet_vec)[0]  \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3337, 'Democratic': 941}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 943, 'Democratic': 4780})})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into features and labels\n",
    "X = [tweet[0] for tweet in tweet_data]  \n",
    "y = [tweet[1] for tweet in tweet_data]  \n",
    "\n",
    "# Vectorize the tweets using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test classifier on a larger dataset and store results\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "# Number of tweets to score\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, actual_party = tp\n",
    "\n",
    "    # Vectorize the tweet for classification\n",
    "    tweet_vec = vectorizer.transform([tweet])\n",
    "\n",
    "    # Estimate the party using the classifier\n",
    "    estimated_party = clf.predict(tweet_vec)[0]\n",
    "\n",
    "    # Update the results dictionary with the actual and estimated party\n",
    "    results[actual_party][estimated_party] += 1\n",
    "\n",
    "    # Break the loop after scoring the specified number of tweets\n",
    "    if idx >= num_to_score:\n",
    "        break\n",
    "\n",
    "# Display the classification results\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "There are some interesting results from the Naïve Bayes classification model. One of the key observations is the overall accuracy of the model. There were 3337 Republican tweets and 941 of them were wrongly classified as Democratic tweets. The misclassification percentage of Republican tweets is 22%. Similarly, there were 4780 Democratic tweets whereas 943 Democratic tweets were classified as Republican tweets. The misclassification percentage is about 16%. This shows that the model will likely misclassify Republican tweets as Democratic tweets. The large common term present in both tweets could also be one of the reasons behind this. The common words of election and parties could confuse this classification model. There are some class imbalances in the tweet dataset as there are more Democratic tweets compared to Republican tweets. Hence the model would target the democratic tweet which is majority class. The class-balanced dataset would produce accurate results.\n",
    "\n",
    "There is also some room for improvement in this classification model. Balancing the tweet dataset so that the model performs better with both minority and majority datasets could enhance the model performance. The use of other algorithms such as SVM, etc., or using tuned hyperparameters along with Naive Bayes could also improve the accuracy while predicting the tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "OpenAI. (2024). ChatGPT (September 29 version) [Large language model]. https://chat.openai.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
